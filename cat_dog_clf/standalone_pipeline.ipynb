{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: Anurag Vaidya  \n",
    "Date: 2/4/2022  \n",
    "Lab: Polina Lab @ CSAIL  \n",
    "Purpose: Create a basic classifier for the afhq dataset\n",
    "\n",
    "## Notebook Structure\n",
    "- Imports\n",
    "- Args\n",
    "- Dataset\n",
    "- Model\n",
    "- Training/ Val loop\n",
    "- main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as Fun\n",
    "import torchvision.transforms.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import models\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "from argparse import Namespace\n",
    "import time, copy\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# import wandb\n",
    "# wandb.init(project=\"cat-dog-styleSpace\", entity=\"ajv012\")\n",
    "\n",
    "\n",
    "sys.path.append(\"./\")\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Namespace(device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\"),\n",
    "                 train_dir = \"../data/afhq/train\",\n",
    "                 val_dir = \"../data/afhq/val\",\n",
    "                 save_path = \"./checkpoints\",\n",
    "                 seed = 7,\n",
    "                 labels = [\"cat\", \"dog\"],\n",
    "                 batch_size = 64,\n",
    "                 epochs = 50,\n",
    "                 num_workers = 0,\n",
    "                 class_names = {0:\"cat\", 1:\"dog\"} ,\n",
    "                 lr = 0.0001,\n",
    "                 momentum = 0.9,\n",
    "                 criterion = nn.CrossEntropyLoss(),\n",
    "                 optimizer = \"SGD\",\n",
    "                 scheduler = \"STEP\",\n",
    "                 scheduler_step_size = 7,\n",
    "                 scheduler_gamma = 0.1,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class afhq_dataset(Dataset):\n",
    "    r\"\"\"\n",
    "    Take a root dir and return the transformed img and associated label with it\n",
    "    \"\"\"\n",
    "    def __init__(self, root_dir, seed, labels, img_transform=None):\n",
    "\n",
    "        self.seed = seed\n",
    "        np.random.seed(self.seed)\n",
    "\n",
    "        # this dir has two sub dirs cat and dog. Need to combine them\n",
    "        self.root_dir = root_dir\n",
    "        self.cat_names = os.listdir(os.path.join(self.root_dir, \"cat\"))\n",
    "        self.dog_names = os.listdir(os.path.join(self.root_dir, \"dog\"))\n",
    "        self.all_names = np.asarray(self.cat_names + self.dog_names)\n",
    "        np.random.shuffle(self.all_names)\n",
    "        self.img_transform = img_transform\n",
    "        self.labels = {}\n",
    "        for i in range(len(labels)):\n",
    "            self.labels[labels[i]] = i\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.all_names)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        curr_path = os.path.join(self.root_dir, self.all_names[idx].strip().split(\"_\")[1], self.all_names[idx])\n",
    "        curr_img = Image.open(curr_path)\n",
    "        curr_label = self.labels[self.all_names[idx].strip().split(\"_\")[1]]\n",
    "        \n",
    "        if self.img_transform:\n",
    "            curr_img_transformed = self.img_transform(curr_img)\n",
    "        \n",
    "        return {\"inputs\" : curr_img_transformed, \"labels\" : curr_label} \n",
    "    \n",
    "    def viz_img(self, imgs):\n",
    "        r\"\"\"\n",
    "        Take a tensor or list of tensors and visualize it\n",
    "        \"\"\"\n",
    "        if not isinstance(imgs, list):\n",
    "            imgs = [imgs]\n",
    "        fig, axs = plt.subplots(ncols=len(imgs), squeeze=False)\n",
    "        for i, img in enumerate(imgs):\n",
    "            img = img.detach()\n",
    "            img = F.to_pil_image(img)\n",
    "            axs[0, i].imshow(np.asarray(img))\n",
    "            axs[0, i].set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])\n",
    "    \n",
    "    def what_labels_mean(self):\n",
    "        return [label + \": \" + str(self.labels[label]) for label in self.labels]\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class clf(torch.nn.Module):\n",
    "    r\"\"\"\n",
    "    A simple encoder and fully connected layer for classification\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_classes):\n",
    "        super(clf, self).__init__()\n",
    "        self.model_ft = models.resnet18(pretrained=True)\n",
    "        self.num_ftrs = self.model_ft.fc.in_features\n",
    "        self.model_ft.fc = nn.Linear(self.num_ftrs, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model_ft(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_val_model(model, datasets, dataloaders, device, criterion, optimizer, scheduler, PATH, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        running_loss_train = 0.0\n",
    "        running_corrects_train = 0\n",
    "\n",
    "        running_loss_val = 0.0\n",
    "        running_corrects_val = 0\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            # Iterate over data.\n",
    "            for batch in dataloaders[phase]:\n",
    "                inputs, labels = batch[\"inputs\"], batch[\"labels\"]\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                if phase == \"train\":\n",
    "                    running_loss_train += loss.item() * inputs.size(0)\n",
    "                    running_corrects_train += torch.sum(preds == labels.data)\n",
    "                else:\n",
    "                    running_loss_val += loss.item() * inputs.size(0)\n",
    "                    running_corrects_val += torch.sum(preds == labels.data)\n",
    "\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            if phase == \"train\":\n",
    "                epoch_loss = running_loss_train / len(datasets[phase])\n",
    "                epoch_acc = running_corrects_train.double() / len(datasets[phase])\n",
    "                wandb.log({\"train_epoch_loss\": epoch_loss, \"train_epoch_acc\": epoch_acc})\n",
    "            else:\n",
    "                epoch_loss = running_loss_val / len(datasets[phase])\n",
    "                epoch_acc = running_corrects_val.double() / len(datasets[phase])\n",
    "                wandb.log({\"val_epoch_loss\": epoch_loss, \"val_epoch_acc\": epoch_acc})\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                # save current best model\n",
    "                PATH = \"{}/checkpoint_{}.pt\".format(args.save_path, epoch)\n",
    "                torch.save({\n",
    "                            'epoch': epoch,\n",
    "                            'model_state_dict': model.state_dict(),\n",
    "                            'optimizer_state_dict': optimizer.state_dict(),\n",
    "                            'loss': epoch_loss,\n",
    "                            'acc' : epoch_acc,\n",
    "                            }, PATH)\n",
    "                wandb.log({\"best_acc\": best_acc})\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_model(model, dataloaders, device, class_names, num_images=6):\n",
    "    was_training = model.training\n",
    "    model.eval()\n",
    "    images_so_far = 0\n",
    "    fig = plt.figure()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in enumerate(dataloaders['val']):\n",
    "            inputs, labels = batch[\"inputs\"], batch[\"labels\"]\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            for j in range(inputs.size()[0]):\n",
    "                images_so_far += 1\n",
    "                ax = plt.subplot(num_images//2, 2, images_so_far)\n",
    "                ax.axis('off')\n",
    "                ax.set_title('predicted: {}'.format(class_names[preds[j]]))\n",
    "                plt.imshow(inputs.cpu().data[j])\n",
    "\n",
    "                if images_so_far == num_images:\n",
    "                    model.train(mode=was_training)\n",
    "                    return\n",
    "        model.train(mode=was_training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def def_transforms():\n",
    "    train_transforms = transforms.Compose([\n",
    "    transforms.Resize(512),\n",
    "    transforms.CenterCrop(512),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "    val_transforms = transforms.Compose([\n",
    "        transforms.Resize(512),\n",
    "        transforms.CenterCrop(512),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "    return train_transforms, val_transforms\n",
    "\n",
    "def def_datasets(args, train_transforms, val_transforms):\n",
    "    dataset_train = afhq_dataset(args.train_dir, args.seed, args.labels, train_transforms)\n",
    "    dataset_val = afhq_dataset(args.val_dir, args.seed, args.labels, val_transforms)\n",
    "    datasets = {\"train\": dataset_train, \"val\": dataset_val}\n",
    "    dataset_sizes = {x: datasets[x] for x in ['train', 'val']}\n",
    "\n",
    "    return datasets, dataset_sizes\n",
    "\n",
    "def def_dataloaders(args, dataset_train, dataset_val):\n",
    "    dataloader_train = DataLoader(dataset_train, batch_size = args.batch_size, num_workers=args.num_workers)\n",
    "    dataloader_val = DataLoader(dataset_val, batch_size = args.batch_size, num_workers=args.num_workers)\n",
    "    dataloaders = {\"train\": dataloader_train, \"val\":dataloader_val}\n",
    "\n",
    "    return dataloaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "\n",
    "    # define transforms\n",
    "    train_transforms, val_transforms = def_transforms()\n",
    "\n",
    "    # define datasets and sizes\n",
    "    datasets, dataset_sizes = def_datasets(args, train_transforms, val_transforms)\n",
    "\n",
    "    # define dataloaders\n",
    "    dataloaders = def_dataloaders(args, datasets[\"train\"], datasets[\"val\"])\n",
    "    \n",
    "    # define model\n",
    "    model = clf(len(args.labels))\n",
    "    model = model.to(args.device)\n",
    "    \n",
    "    # define criterion\n",
    "    criterion = args.criterion\n",
    "    \n",
    "    # define optim\n",
    "    if args.optimizer == \"SGD\":\n",
    "        optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum)\n",
    "    \n",
    "    # define lr scheduler\n",
    "    if args.scheduler == \"STEP\":\n",
    "        scheduler = lr_scheduler.StepLR(optimizer, step_size=args.scheduler_step_size, gamma=args.scheduler_gamma)\n",
    "\n",
    "    # logging\n",
    "    wandb.config = {\n",
    "                    \"learning_rate\": args.lr,\n",
    "                    \"epochs\": args.epochs,\n",
    "                    \"batch_size\": args.batch_size\n",
    "    }\n",
    "    \n",
    "    # train and val model\n",
    "    model_final = train_and_val_model(model, datasets, dataloaders, args.device, \n",
    "                                     criterion, optimizer, scheduler, args.save_path, args.epochs)\n",
    "\n",
    "    visualize_model(model_final, dataloaders, args.device, args.class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/49\n",
      "----------\n",
      "train Loss: 0.3838 Acc: 0.9092\n",
      "val Loss: 0.1920 Acc: 0.9940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1/50 [02:37<2:08:15, 157.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/49\n",
      "----------\n",
      "train Loss: 0.1434 Acc: 0.9929\n",
      "val Loss: 0.0911 Acc: 0.9980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 2/50 [05:10<2:04:06, 155.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2/49\n",
      "----------\n",
      "train Loss: 0.0813 Acc: 0.9969\n",
      "val Loss: 0.0562 Acc: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 3/50 [07:51<2:03:25, 157.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3/49\n",
      "----------\n",
      "train Loss: 0.0554 Acc: 0.9975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 4/50 [10:21<1:58:34, 154.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0395 Acc: 1.0000\n",
      "\n",
      "Epoch 4/49\n",
      "----------\n",
      "train Loss: 0.0417 Acc: 0.9981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 5/50 [12:51<1:54:36, 152.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0301 Acc: 1.0000\n",
      "\n",
      "Epoch 5/49\n",
      "----------\n",
      "train Loss: 0.0333 Acc: 0.9985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 6/50 [15:23<1:51:59, 152.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0241 Acc: 1.0000\n",
      "\n",
      "Epoch 6/49\n",
      "----------\n",
      "train Loss: 0.0276 Acc: 0.9986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 7/50 [17:55<1:49:11, 152.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0200 Acc: 1.0000\n",
      "\n",
      "Epoch 7/49\n",
      "----------\n",
      "train Loss: 0.0251 Acc: 0.9986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 8/50 [20:25<1:46:14, 151.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0197 Acc: 1.0000\n",
      "\n",
      "Epoch 8/49\n",
      "----------\n",
      "train Loss: 0.0247 Acc: 0.9987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 9/50 [22:57<1:43:48, 151.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0194 Acc: 1.0000\n",
      "\n",
      "Epoch 9/49\n",
      "----------\n",
      "train Loss: 0.0243 Acc: 0.9987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 10/50 [25:29<1:41:07, 151.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0191 Acc: 1.0000\n",
      "\n",
      "Epoch 10/49\n",
      "----------\n",
      "train Loss: 0.0240 Acc: 0.9987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 11/50 [27:59<1:38:20, 151.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0188 Acc: 1.0000\n",
      "\n",
      "Epoch 11/49\n",
      "----------\n",
      "train Loss: 0.0236 Acc: 0.9987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 12/50 [30:30<1:35:43, 151.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0185 Acc: 1.0000\n",
      "\n",
      "Epoch 12/49\n",
      "----------\n",
      "train Loss: 0.0233 Acc: 0.9987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 13/50 [32:59<1:32:49, 150.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0182 Acc: 1.0000\n",
      "\n",
      "Epoch 13/49\n",
      "----------\n",
      "train Loss: 0.0230 Acc: 0.9987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 14/50 [35:28<1:30:05, 150.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0179 Acc: 1.0000\n",
      "\n",
      "Epoch 14/49\n",
      "----------\n",
      "train Loss: 0.0228 Acc: 0.9987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 15/50 [37:59<1:27:37, 150.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0179 Acc: 1.0000\n",
      "\n",
      "Epoch 15/49\n",
      "----------\n",
      "train Loss: 0.0228 Acc: 0.9987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 16/50 [40:30<1:25:18, 150.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0178 Acc: 1.0000\n",
      "\n",
      "Epoch 16/49\n",
      "----------\n",
      "train Loss: 0.0227 Acc: 0.9987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 17/50 [43:03<1:23:09, 151.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0178 Acc: 1.0000\n",
      "\n",
      "Epoch 17/49\n",
      "----------\n",
      "train Loss: 0.0227 Acc: 0.9987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 18/50 [45:31<1:20:13, 150.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0178 Acc: 1.0000\n",
      "\n",
      "Epoch 18/49\n",
      "----------\n",
      "train Loss: 0.0227 Acc: 0.9987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 19/50 [48:01<1:17:39, 150.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0178 Acc: 1.0000\n",
      "\n",
      "Epoch 19/49\n",
      "----------\n",
      "train Loss: 0.0226 Acc: 0.9987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 20/50 [50:32<1:15:08, 150.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0177 Acc: 1.0000\n",
      "\n",
      "Epoch 20/49\n",
      "----------\n",
      "train Loss: 0.0226 Acc: 0.9987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 21/50 [53:01<1:12:32, 150.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0177 Acc: 1.0000\n",
      "\n",
      "Epoch 21/49\n",
      "----------\n",
      "train Loss: 0.0226 Acc: 0.9987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 22/50 [55:32<1:10:06, 150.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0177 Acc: 1.0000\n",
      "\n",
      "Epoch 22/49\n",
      "----------\n",
      "train Loss: 0.0226 Acc: 0.9987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 23/50 [58:01<1:07:25, 149.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0177 Acc: 1.0000\n",
      "\n",
      "Epoch 23/49\n",
      "----------\n",
      "train Loss: 0.0226 Acc: 0.9987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 24/50 [1:00:32<1:05:11, 150.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0177 Acc: 1.0000\n",
      "\n",
      "Epoch 24/49\n",
      "----------\n",
      "train Loss: 0.0226 Acc: 0.9987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 25/50 [1:03:02<1:02:34, 150.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0177 Acc: 1.0000\n",
      "\n",
      "Epoch 25/49\n",
      "----------\n",
      "train Loss: 0.0226 Acc: 0.9987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 26/50 [1:05:31<59:53, 149.75s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0177 Acc: 1.0000\n",
      "\n",
      "Epoch 26/49\n",
      "----------\n",
      "train Loss: 0.0226 Acc: 0.9987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 27/50 [1:08:01<57:25, 149.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0177 Acc: 1.0000\n",
      "\n",
      "Epoch 27/49\n",
      "----------\n",
      "train Loss: 0.0226 Acc: 0.9987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 28/50 [1:10:31<55:01, 150.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0177 Acc: 1.0000\n",
      "\n",
      "Epoch 28/49\n",
      "----------\n",
      "train Loss: 0.0226 Acc: 0.9987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 29/50 [1:13:01<52:28, 149.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0177 Acc: 1.0000\n",
      "\n",
      "Epoch 29/49\n",
      "----------\n",
      "train Loss: 0.0226 Acc: 0.9987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 30/50 [1:15:33<50:10, 150.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0177 Acc: 1.0000\n",
      "\n",
      "Epoch 30/49\n",
      "----------\n",
      "train Loss: 0.0226 Acc: 0.9987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 31/50 [1:18:03<47:36, 150.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0177 Acc: 1.0000\n",
      "\n",
      "Epoch 31/49\n",
      "----------\n",
      "train Loss: 0.0226 Acc: 0.9987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 32/50 [1:20:34<45:08, 150.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0177 Acc: 1.0000\n",
      "\n",
      "Epoch 32/49\n",
      "----------\n",
      "train Loss: 0.0226 Acc: 0.9987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 33/50 [1:23:04<42:38, 150.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0177 Acc: 1.0000\n",
      "\n",
      "Epoch 33/49\n",
      "----------\n",
      "train Loss: 0.0226 Acc: 0.9987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 34/50 [1:25:36<40:15, 150.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0177 Acc: 1.0000\n",
      "\n",
      "Epoch 34/49\n",
      "----------\n",
      "train Loss: 0.0226 Acc: 0.9987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 35/50 [1:28:07<37:42, 150.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0177 Acc: 1.0000\n",
      "\n",
      "Epoch 35/49\n",
      "----------\n",
      "train Loss: 0.0226 Acc: 0.9987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 36/50 [1:30:38<35:15, 151.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0177 Acc: 1.0000\n",
      "\n",
      "Epoch 36/49\n",
      "----------\n",
      "train Loss: 0.0226 Acc: 0.9987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 37/50 [1:33:07<32:36, 150.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0177 Acc: 1.0000\n",
      "\n",
      "Epoch 37/49\n",
      "----------\n",
      "train Loss: 0.0226 Acc: 0.9987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 38/50 [1:35:37<30:00, 150.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0177 Acc: 1.0000\n",
      "\n",
      "Epoch 38/49\n",
      "----------\n",
      "train Loss: 0.0226 Acc: 0.9987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 39/50 [1:38:07<27:33, 150.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0177 Acc: 1.0000\n",
      "\n",
      "Epoch 39/49\n",
      "----------\n",
      "train Loss: 0.0226 Acc: 0.9987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 40/50 [1:40:38<25:03, 150.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0177 Acc: 1.0000\n",
      "\n",
      "Epoch 40/49\n",
      "----------\n",
      "train Loss: 0.0226 Acc: 0.9987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 41/50 [1:43:08<22:31, 150.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0177 Acc: 1.0000\n",
      "\n",
      "Epoch 41/49\n",
      "----------\n",
      "train Loss: 0.0226 Acc: 0.9987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 42/50 [1:45:37<20:00, 150.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0177 Acc: 1.0000\n",
      "\n",
      "Epoch 42/49\n",
      "----------\n",
      "train Loss: 0.0226 Acc: 0.9987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 43/50 [1:48:09<17:33, 150.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0177 Acc: 1.0000\n",
      "\n",
      "Epoch 43/49\n",
      "----------\n",
      "train Loss: 0.0226 Acc: 0.9987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 44/50 [1:50:41<15:05, 150.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0177 Acc: 1.0000\n",
      "\n",
      "Epoch 44/49\n",
      "----------\n",
      "train Loss: 0.0226 Acc: 0.9987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 45/50 [1:53:11<12:33, 150.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0177 Acc: 1.0000\n",
      "\n",
      "Epoch 45/49\n",
      "----------\n",
      "train Loss: 0.0226 Acc: 0.9987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 46/50 [1:55:47<10:08, 152.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0177 Acc: 1.0000\n",
      "\n",
      "Epoch 46/49\n",
      "----------\n",
      "train Loss: 0.0226 Acc: 0.9987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 47/50 [1:58:17<07:35, 151.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0177 Acc: 1.0000\n",
      "\n",
      "Epoch 47/49\n",
      "----------\n",
      "train Loss: 0.0226 Acc: 0.9987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 48/50 [2:00:49<05:03, 151.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0177 Acc: 1.0000\n",
      "\n",
      "Epoch 48/49\n",
      "----------\n",
      "train Loss: 0.0226 Acc: 0.9987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 49/50 [2:03:19<02:31, 151.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0177 Acc: 1.0000\n",
      "\n",
      "Epoch 49/49\n",
      "----------\n",
      "train Loss: 0.0226 Acc: 0.9987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [2:05:50<00:00, 151.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0177 Acc: 1.0000\n",
      "\n",
      "Training complete in 125m 50s\n",
      "Best val Acc: 1.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "tuple indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_22892/451043146.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_22892/712207665.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m                                      criterion, optimizer, scheduler, args.save_path, args.epochs)\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0mvisualize_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_final\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_22892/2226766549.py\u001b[0m in \u001b[0;36mvisualize_model\u001b[0;34m(model, dataloaders, device, class_names, num_images)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"inputs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"labels\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m             \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: tuple indices must be integers or slices, not str"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9bbb49dca6fd3fb5150bec4959f4b143d84da4fc3f17c9f888243ead3e503560"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('styleSpace')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
